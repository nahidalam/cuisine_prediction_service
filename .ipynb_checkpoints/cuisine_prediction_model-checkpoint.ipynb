{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, log_loss, roc_auc_score\n",
    "import scipy\n",
    "import csv\n",
    "import pickle\n",
    "#import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('./cuisine.train.v2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]\n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             # of Rows, Columns: (39774, 3)\n",
      "             Total missing  Percent missing\n",
      "ingredients              0              0.0\n",
      "id                       0              0.0\n",
      "cuisine                  0              0.0\n"
     ]
    }
   ],
   "source": [
    "#train=train_df\n",
    "total = train.isnull().sum().sort_values(ascending = False)\n",
    "percent = (train.isnull().sum()/train.isnull().count()*100).sort_values(ascending = False)\n",
    "missing_train_data  = pd.concat([total, percent], axis=1, keys=['Total missing', 'Percent missing'])\n",
    "print(\"             # of Rows, Columns:\",train.shape)\n",
    "print(missing_train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So looks like there is no null value in the train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(input_file):\n",
    "    import json\n",
    "    import re\n",
    "    from pandas.io.json import json_normalize\n",
    "    corpus_file = open(input_file,\"r\")\n",
    "    corpus = corpus_file.read()\n",
    "    entries =  json.loads(corpus)\n",
    "    df =  json_normalize(entries)\n",
    "    df['flat_ingredients'] = df.apply(lambda row: ' '.join(ingredient for ingredient in row['ingredients']), axis=1)\n",
    "    df['word_count'] = df.apply(lambda row: len(row['flat_ingredients'].split(' ')), axis=1)\n",
    "    df.drop('ingredients', axis=1, inplace=True)   \n",
    "    df.sort_values(['word_count'], ascending=False, inplace=True)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flatten=flatten_json('./cuisine.train.v2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>flat_ingredients</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15289</th>\n",
       "      <td>italian</td>\n",
       "      <td>3885</td>\n",
       "      <td>fettucine fresh marjoram minced garlic olive o...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30350</th>\n",
       "      <td>brazilian</td>\n",
       "      <td>13430</td>\n",
       "      <td>marshmallows fresh corn cheddar cheese shredde...</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26103</th>\n",
       "      <td>mexican</td>\n",
       "      <td>13049</td>\n",
       "      <td>vanilla ice cream lime garlic powder zucchini ...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10513</th>\n",
       "      <td>mexican</td>\n",
       "      <td>49282</td>\n",
       "      <td>condensed cream of chicken soup pepper refried...</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6449</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>6548</td>\n",
       "      <td>canned black beans seasoned bread crumbs prepa...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cuisine     id                                   flat_ingredients  \\\n",
       "15289      italian   3885  fettucine fresh marjoram minced garlic olive o...   \n",
       "30350    brazilian  13430  marshmallows fresh corn cheddar cheese shredde...   \n",
       "26103      mexican  13049  vanilla ice cream lime garlic powder zucchini ...   \n",
       "10513      mexican  49282  condensed cream of chicken soup pepper refried...   \n",
       "6449   southern_us   6548  canned black beans seasoned bread crumbs prepa...   \n",
       "\n",
       "       word_count  \n",
       "15289         136  \n",
       "30350         107  \n",
       "26103         105  \n",
       "10513         102  \n",
       "6449           88  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_flatten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the input for the model\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "train_transform = tfidf_vect.fit_transform(train_flatten['flat_ingredients'])\n",
    "le = preprocessing.LabelEncoder()\n",
    "X = train_transform\n",
    "y = le.fit_transform(train_flatten['cuisine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the vectorizer for future use\n",
    "\n",
    "pickle.dump(tfidf_vect, open(\"vectorizer.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train set to train and valid\n",
    "\n",
    "#X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "\n",
    "#print('training score:', f1_score(y_train, rf.predict(X_train), average='macro'))\n",
    "#print('validation score:', f1_score(y_valid, rf.predict(X_valid), average='macro'))\n",
    "#print(classification_report(y_valid, xgb_prediction))\n",
    "\n",
    "rf.fit(X, y)\n",
    "#rf.fit(X_train, y_train)\n",
    "#predicted_labels = rf.predict(X_valid)\n",
    "#print (\"FINISHED classifying. accuracy score : \")\n",
    "#print (accuracy_score(y_valid, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model for future use\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(rf, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flat_ingredients</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>sugar egg yolks corn starch cream of tartar ba...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>baking powder eggs all-purpose flour raisins m...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                   flat_ingredients  word_count\n",
       "1  28583  sugar egg yolks corn starch cream of tartar ba...          20\n",
       "0  18009  baking powder eggs all-purpose flour raisins m...           9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = flatten_json('./test2.json')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 9]\n",
      "[[0.01256878 0.02309934 0.03749478 0.07811859 0.01927727 0.07127609\n",
      "  0.02632433 0.06620387 0.01780258 0.17846839 0.012995   0.03381639\n",
      "  0.02042203 0.16786254 0.01720543 0.01338107 0.12414803 0.02345183\n",
      "  0.03641069 0.01967298]\n",
      " [0.01270265 0.02515649 0.03949825 0.06030703 0.01915204 0.07322007\n",
      "  0.0290996  0.0718222  0.02037151 0.19187031 0.01408462 0.03239637\n",
      "  0.01921427 0.14901947 0.01883097 0.01442608 0.12805732 0.02484447\n",
      "  0.03656362 0.01936266]]\n"
     ]
    }
   ],
   "source": [
    "vect = pickle.load(open(\"vectorizer.pickle\", \"rb\"))\n",
    "test_transform = vect.transform(test['flat_ingredients'].values)\n",
    "X_test = test_transform\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "predicted_labels = loaded_model.predict(X_test)\n",
    "predicted_proba = loaded_model.predict_proba(X_test)\n",
    "print(predicted_labels)\n",
    "print(predicted_proba)\n",
    "#print(predicted_proba[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{9: 'italian', 0: 'italian', 13: 'mexican', 16: 'mexican', 18: 'cajun_creole', 4: 'southern_us', 3: 'mexican', 17: 'mexican', 7: 'filipino', 2: 'mexican', 14: 'brazilian', 10: 'spanish', 1: 'brazilian', 19: 'mexican', 11: 'indian', 5: 'thai', 6: 'italian', 12: 'indian', 8: 'chinese', 15: 'mexican'}\n"
     ]
    }
   ],
   "source": [
    "# create a mapping and save in a csv\n",
    "hashMap = {}\n",
    "for item in y:\n",
    "    if item in hashMap:\n",
    "        continue\n",
    "    else:\n",
    "        index = item\n",
    "        hashMap[item] = train_flatten['cuisine'].values[index]\n",
    "\n",
    "print (hashMap)\n",
    "\n",
    "# save the map in a csv file\n",
    "\n",
    "with open('cuisine_dict.csv', 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in hashMap.items():\n",
    "       writer.writerow([key, value])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
